{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ae89a56",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import dependencies & define prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b3453205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64, json, re, copy\n",
    "from pathlib import Path\n",
    "\n",
    "def image_file_to_data_url(img_path: str) -> str:\n",
    "    p = Path(img_path)\n",
    "    mime = \"image/png\" if p.suffix.lower() == \".png\" else \"image/jpeg\"\n",
    "    b64 = base64.b64encode(p.read_bytes()).decode(\"utf-8\")\n",
    "    return f\"data:{mime};base64,{b64}\"\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"# Tools\n",
    "\n",
    "You may call one or more functions to assist with the user query.\n",
    "\n",
    "You are provided with function signatures within <tools></tools> XML tags:\n",
    "<tools>\n",
    "{\"type\":\"function\",\"function\":{\"name_for_human\":\"mobile_use\",\"name\":\"mobile_use\",\"description\":\"Use a touchscreen to interact with a mobile device, and take screenshots.\\n* This is an interface to a mobile device with touchscreen. You can perform actions like clicking, typing, swiping, etc.\\n* Some applications may take time to start or process actions, so you may need to wait and take successive screenshots to see the results of your actions.\\n* The screen's resolution is 1000x1000.\\n* Make sure to click any buttons, links, icons, etc with the cursor tip in the center of the element. Don't click boxes on their edges unless asked.\",\"parameters\":{\"properties\":{\"action\":{\"description\":\"The action to perform.\",\"enum\":[\"key\",\"click\",\"long_press\",\"swipe\",\"type\",\"system_button\",\"open\",\"wait\",\"terminate\"],\"type\":\"string\"},\"coordinate\":{\"type\":\"array\"},\"coordinate2\":{\"type\":\"array\"},\"text\":{\"type\":\"string\"},\"time\":{\"type\":\"number\"},\"button\":{\"enum\":[\"Back\",\"Home\",\"Menu\",\"Enter\"],\"type\":\"string\"},\"status\":{\"enum\":[\"success\",\"failure\"],\"type\":\"string\"}},\"required\":[\"action\"],\"type\":\"object\"},\"args_format\":\"Format the arguments as a JSON object.\"}}\n",
    "</tools>\n",
    "\n",
    "For each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\n",
    "<tool_call>\n",
    "{\"name\": <function-name>, \"arguments\": <args-json-object>}\n",
    "</tool_call>\n",
    "\n",
    "# Response format\n",
    "\n",
    "Response format for every step:\n",
    "1) Action: a short imperative describing what to do in the UI.\n",
    "2) A single <tool_call>...</tool_call> block containing only the JSON: {\"name\": <function-name>, \"arguments\": <args-json-object>}.\n",
    "\n",
    "Rules:\n",
    "- Output exactly in the order: Action, <tool_call>.\n",
    "- Be brief: one for Action.\n",
    "- Do not output anything else outside those two parts.\n",
    "- If finishing, use action=terminate in the tool call.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b6d613",
   "metadata": {},
   "source": [
    "### Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "78848c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_action_line(assistant_text: str) -> str | None:\n",
    "    m = re.search(r\"Action:\\s*(.+)\", assistant_text)\n",
    "    if not m:\n",
    "        return None\n",
    "    return m.group(1).strip()\n",
    "\n",
    "def build_initial_user_text(goal: str, previous_actions: list[str]) -> str:\n",
    "    if not previous_actions:\n",
    "        prev = \"No previous action.\"\n",
    "    else:\n",
    "        prev = \"\\n\".join([f\"Step{i+1}: {a}\" for i, a in enumerate(previous_actions)])\n",
    "    return (\n",
    "        \"Please generate the next move according to the UI screenshot, instruction and previous actions.\\n\\n\"\n",
    "        f\"Instruction: {goal}\\n\\n\"\n",
    "        f\"Previous actions:\\n{prev}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6c4e1c",
   "metadata": {},
   "source": [
    "### Model server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e801fc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "VLLM_BASE_URL = \"http://YOUR_VLLM_HOST:8000/v1\"\n",
    "VLLM_API_KEY = \"YOUR_API_KEY\"\n",
    "MODEL_NAME = \"YOUR_MODEL_NAME\"\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=VLLM_BASE_URL,\n",
    "    api_key=VLLM_API_KEY,\n",
    ")\n",
    "\n",
    "def call_model(messages: list[dict]) -> str:\n",
    "    resp = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    return resp.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc56aef2",
   "metadata": {},
   "source": [
    "### Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388416cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAST_IMAGE_TURNS = 5\n",
    "goal = \"Turn on the dark mode\"\n",
    "previous_actions = []\n",
    "\n",
    "img_path = \"screenshot_1.png\"\n",
    "data_url_1 = image_file_to_data_url(img_path)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": SYSTEM_PROMPT}]},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": build_initial_user_text(goal, previous_actions)},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": data_url_1}},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "assistant_text_1 = call_model(messages)\n",
    "print(assistant_text_1)\n",
    "\n",
    "messages.append({\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": assistant_text_1}]})\n",
    "previous_actions.append(extract_action_line(assistant_text_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2199a635",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff87fe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = f\"screenshot_2.png\"\n",
    "data_url_2 = image_file_to_data_url(img_path)\n",
    "\n",
    "messages.append(\n",
    "    {\"role\": \"user\", \"content\": [{\"type\": \"image_url\", \"image_url\": {\"url\": data_url_2}}]}\n",
    ")\n",
    "\n",
    "cur_messages = copy.deepcopy(messages)\n",
    "\n",
    "if len(previous_actions) > LAST_IMAGE_TURNS - 1:\n",
    "    cur_previous_actions = previous_actions[-(len(previous_actions) - LAST_IMAGE_TURNS + 1):]\n",
    "    cur_messages_current = cur_messages[-(2 * LAST_IMAGE_TURNS -1):]\n",
    "    cur_messages[1][\"content\"][0][\"text\"] = build_initial_user_text(goal, cur_previous_actions)\n",
    "    del cur_messages[1][\"content\"][1]\n",
    "    cur_messages = cur_messages[:2] + cur_messages_current\n",
    "    cur_messages[1][\"content\"].append(cur_messages[2][\"content\"][0])\n",
    "    del cur_messages[2]\n",
    "\n",
    "assistant_text_2 = call_model(cur_messages)\n",
    "print(assistant_text_2)\n",
    "\n",
    "messages.append({\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": assistant_text_2}]})\n",
    "\n",
    "previous_actions.append(extract_action_line(assistant_text_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ccf6c6",
   "metadata": {},
   "source": [
    "### ......\n",
    "### Step n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ad6c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = f\"screenshot_n.png\"\n",
    "data_url_n = image_file_to_data_url(img_path)\n",
    "\n",
    "messages.append(\n",
    "    {\"role\": \"user\", \"content\": [{\"type\": \"image_url\", \"image_url\": {\"url\": data_url_n}}]}\n",
    ")\n",
    "\n",
    "cur_messages = copy.deepcopy(messages)\n",
    "\n",
    "if len(previous_actions) > LAST_IMAGE_TURNS - 1:\n",
    "    cur_previous_actions = previous_actions[-(len(previous_actions) - LAST_IMAGE_TURNS + 1):]\n",
    "    cur_messages_current = cur_messages[-(2 * LAST_IMAGE_TURNS -1):]\n",
    "    cur_messages[1][\"content\"][0][\"text\"] = build_initial_user_text(goal, cur_previous_actions)\n",
    "    del cur_messages[1][\"content\"][1]\n",
    "    cur_messages = cur_messages[:2] + cur_messages_current\n",
    "    cur_messages[1][\"content\"].append(cur_messages[2][\"content\"][0])\n",
    "    del cur_messages[2]\n",
    "\n",
    "assistant_text_n = call_model(cur_messages)\n",
    "print(assistant_text_n)\n",
    "\n",
    "messages.append({\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": assistant_text_n}]})\n",
    "\n",
    "previous_actions.append(extract_action_line(assistant_text_n))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
